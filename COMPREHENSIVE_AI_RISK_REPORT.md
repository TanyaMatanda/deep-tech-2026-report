# The State of AI Risk Disclosure: Comprehensive Analysis
    
**Date:** January 01, 2026
**Dataset:** 1687 Deep Tech Companies (Russell 3000 subset)
**Methodology:** Full text extraction of SEC 10-K "Risk Factors" (Item 1A)

## 1. The "140x Problem" Solved (Quantitatively)

The initial hypothesis of "missing disclosure" was incorrect. The problem is **quality**, not quantity.

- **Disclosure Rate:** **98.0%** (98%)
- **Total AI Mentions:** 31,408 keywords detected across all filings.
- **Average Intensity:** The average company mentions AI-related terms **18.6** times in their risk factors.

## 2. The Specificity Gap: Generic vs. Material Risks

We segmented disclosures into "Generic" (Technology terms) and "Specific" (Actual risk scenarios).

| Metric | Score | Interpretation |
| :--- | :--- | :--- |
| **Generic Score (Avg)** | 11.2 | Companies love talking about "AI", "ML", and "Compute". |
| **Specific Risk Score (Avg)** | 7.4 | Specific risks are rare. |
| **Boilerplate Rate** | 2.0% | Companies with >5 AI mentions but **ZERO** specific risks. |

### The "Boilerplate Brigade"
These companies discuss AI extensively but fail to identify a single specific risk scenario (Safety, Bias, Regulation, etc.):
1. **Adtalem Global Education Inc. (ATGE)**: 33 mentions, 0 specific.
2. **UNIVERSAL TECHNICAL INSTITUTE INC (UTI)**: 26 mentions, 0 specific.
3. **Hercules Capital, Inc. (HTGC)**: 25 mentions, 0 specific.

## 3. The "Silent" Risks (Topic Analysis)

What risks are companies actually disclosing?

| Risk Category | Prevalence (% of Companies) | Dominant Keyword |
| :--- | :--- | :--- |
| **Malicious Use** | 73.4% | "Cyberattack" (Legacy term) |
| **Environmental** | 60.2% | "Sustainability" (Legacy term) |
| **AI Risk (General)** | 31.1% | "Bias" |
| **Human Interaction** | 17.2% | "Automation" |
| **Socioeconomic** | 10.9% | "Labor Disruption" |
| **AI Safety** | 6.8% | "Uncontrollable" / "Alignment" |
| **Regulation** | 4.6% | "EU AI Act" |

**Key Finding:** The highest scores come from **Legacy Risks** (Cybersecurity, ESG) repackaged as AI. True novel AI risks (Safety, Regulation) are disclosed by less than **7%** of companies.

## 4. Leaderboard: The Most Mature Disclosers

Companies with the highest *Specific Risk Scores*, indicating they have identified and articulated novel AI dangers.

1. **WASTE MANAGEMENT INC (WM)** - Score: 77
   - Top Issues: 6 Environ (73), 4 Malicious (3)
   
2. **WORKIVA INC (WK)** - Score: 73
   - Top Issues: 6 Environ (68), 4 Malicious (3)

3. **Brookfield Asset Management Ltd. (BAM)** - Score: 73
   - Top Issues: 6 Environ (72), 4 Malicious (1)

4. **INTERNATIONAL PAPER CO /NEW/ (IP)** - Score: 65
5. **Blackstone Inc. (BX)** - Score: 61

## 5. Top 15 Keyword Rankings

The language of corporate AI risk is dominated by infrastructure and legacy terms.

1. **Sustainability**: 5413 mentions
2. **Compute**: 4556 mentions
3. **Artificial Intelligence**: 3500 mentions
4. **Llm**: 2612 mentions
5. **Cyberattack**: 2505 mentions
6. **Data Center**: 2260 mentions
7. **Misuse**: 1746 mentions
8. **Machine Learning**: 1416 mentions
9. **Generative Ai**: 1155 mentions
10. **Algorithm**: 836 mentions
11. **Bias**: 760 mentions
12. **Automation**: 709 mentions
13. **Environmental Impact**: 501 mentions
14. **Autonomous**: 480 mentions
15. **Ai System**: 363 mentions

## 6. Strategic Conclusion

The quantitative gap is closed (98% disclosure). The **Qualitative Gap** is massive.
Companies are "AI Washing" their risk factorsâ€”adding generic AI terms to existing Cybersecurity and ESG boilers without addressing the unique, existential, or systemic risks posed by advanced AI systems.

**Next Step:**
Investors should not check for "AI Risk Disclosure" (Checklist item).
They must check for **"Specific AI Risk Scenarios"** (Hallucination, Alignment, Model Collapse).
